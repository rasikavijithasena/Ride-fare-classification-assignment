{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fare-classification-msc2020/meta_data.csv\n",
      "/kaggle/input/inputdata/test.csv\n",
      "/kaggle/input/inputdata/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/inputdata/train.csv')\n",
    "test = pd.read_csv('../input/inputdata/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols = ['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'fare']\n",
    "train_X = train[predictor_cols]\n",
    "test_X = test[predictor_cols]\n",
    "\n",
    "#train_y.fillna(train_y.mean(), inplace=True)\n",
    "train.fillna(train_X.mean(), inplace=True)\n",
    "test.fillna(test_X.mean(), inplace=True)\n",
    "train['num_label'] = False\n",
    "train['direct_distance'] = 0.0\n",
    "test['direct_distance'] = 0.0\n",
    "\n",
    "train['pickup_time'] = pd.to_datetime(train['pickup_time'], errors='coerce')\n",
    "test['pickup_time'] = pd.to_datetime(test['pickup_time'], errors='coerce')\n",
    "\n",
    "train['drop_time'] = pd.to_datetime(train['drop_time'], errors='coerce')\n",
    "test['drop_time'] = pd.to_datetime(test['drop_time'], errors='coerce')\n",
    "\n",
    "train['pick_hour'] = train['pickup_time'].dt.hour\n",
    "train['drop_hour'] = train['drop_time'].dt.hour\n",
    "\n",
    "test['pick_hour'] = test['pickup_time'].dt.hour\n",
    "test['drop_hour'] = test['drop_time'].dt.hour\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (row['drop_lat'], row['drop_lon'], row['pick_lat'], row['pick_lon']))\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * 6371 * np.arcsin(np.sqrt(d))\n",
    "    train.at[index,'direct_distance'] = 2 * 6371 * np.arcsin(np.sqrt(d))\n",
    "    #d = (((row['drop_lon'] - row['pick_lon'])**2)+((row['drop_lat'] - row['pick_lat'])**2))\n",
    "    #train.at[index,'direct_distance'] = 2 * 6371 * np.arcsin()\n",
    "    \n",
    "for index, row in test.iterrows():\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (row['drop_lat'], row['drop_lon'], row['pick_lat'], row['pick_lon']))\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * 6371 * np.arcsin(np.sqrt(d))\n",
    "    test.at[index,'direct_distance'] = 2 * 6371 * np.arcsin(np.sqrt(d))\n",
    "    \n",
    "train['fare_for_duration'] = (train['fare'] - train['meter_waiting_fare'])/train['duration']\n",
    "#train['fare_for_distance'] = (train['fare'] - train['meter_waiting_fare'])/train['direct_distance']\n",
    "train['fare_for_time'] = (train['fare'] - train['meter_waiting_fare'])/(train['duration']+train['meter_waiting_till_pickup'])\n",
    "#train['distance_for_time'] = train['direct_distance']/train['duration']\n",
    "train['meter_waiting_to_duration'] = train['meter_waiting']/train['duration']\n",
    "train['additional_fare_to_duration'] = train['additional_fare']/train['duration']\n",
    "#train['additional_fare_to_distance'] = train['additional_fare']/train['direct_distance']\n",
    "train['additional_fare_to_fare'] = train['additional_fare']/(train['fare']+train['additional_fare'])\n",
    "train['mtr_wating_fare_to_waiting_duration'] = train['meter_waiting_fare']/(train['meter_waiting']+train['meter_waiting_till_pickup'])\n",
    "train['additional_fare_to_full_time'] = train['additional_fare']/(train['meter_waiting']+train['meter_waiting_till_pickup']+train['duration'])\n",
    "train['full_waiting_fare_to_full_time'] = (train['meter_waiting_fare']+train['additional_fare'])/(train['meter_waiting']+train['meter_waiting_till_pickup']+train['duration'])\n",
    "train['net_fare_for_durtion'] = (train['fare'] - (train['additional_fare']+train['meter_waiting_fare']))/train['duration']\n",
    "\n",
    "\n",
    "test['fare_for_duration'] = (test['fare'] - test['meter_waiting_fare'])/test['duration']\n",
    "#test['fare_for_distance'] = (test['fare'] - test['meter_waiting_fare'])/test['direct_distance']\n",
    "test['fare_for_time'] = (test['fare'] - test['meter_waiting_fare'])/(test['duration']+test['meter_waiting_till_pickup'])\n",
    "#test['distance_for_time'] = test['direct_distance']/test['duration']\n",
    "test['meter_waiting_to_duration'] = test['meter_waiting']/test['duration']\n",
    "test['additional_fare_to_duration'] = test['additional_fare']/test['duration']\n",
    "#test['additional_fare_to_distance'] = test['additional_fare']/test['direct_distance']\n",
    "test['additional_fare_to_fare'] = test['additional_fare']/(test['fare']+test['additional_fare'])\n",
    "test['mtr_wating_fare_to_waiting_duration'] = test['meter_waiting_fare']/(test['meter_waiting']+test['meter_waiting_till_pickup'])\n",
    "test['additional_fare_to_full_time'] = test['additional_fare']/(test['meter_waiting']+test['meter_waiting_till_pickup']+test['duration'])\n",
    "test['full_waiting_fare_to_full_time'] = (test['meter_waiting_fare']+test['additional_fare'])/(test['meter_waiting']+test['meter_waiting_till_pickup']+test['duration'])\n",
    "test['net_fare_for_durtion'] = (test['fare'] - (test['additional_fare']+test['meter_waiting_fare']))/test['duration']\n",
    "\n",
    "\n",
    "train.replace([np.inf, -np.inf], np.nan)\n",
    "test.replace([np.inf, -np.inf], np.nan)\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "\n",
    "train['fare_for_duration'] = train['fare_for_duration'].astype(np.float32)\n",
    "#train['fare_for_distance'] = train['fare_for_distance'].astype(np.float32)\n",
    "train['fare_for_time'] = train['fare_for_time'].astype(np.float32)\n",
    "#train['distance_for_time'] = train['distance_for_time'].astype(np.float32)\n",
    "train['meter_waiting_to_duration'] = train['meter_waiting_to_duration'].astype(np.float32)\n",
    "train['additional_fare_to_duration'] = train['additional_fare_to_duration'].astype(np.float32)\n",
    "#train['additional_fare_to_distance'] = train['additional_fare_to_distance'].astype(np.float32)\n",
    "train['additional_fare_to_fare'] = train['additional_fare_to_fare'].astype(np.float32)\n",
    "train['mtr_wating_fare_to_waiting_duration'] = train['mtr_wating_fare_to_waiting_duration'].astype(np.float32)\n",
    "train['additional_fare_to_full_time'] = train['additional_fare_to_full_time'].astype(np.float32)\n",
    "train['full_waiting_fare_to_full_time'] = train['full_waiting_fare_to_full_time'].astype(np.float32)\n",
    "train['net_fare_for_durtion'] = train['net_fare_for_durtion'].astype(np.float32)\n",
    "\n",
    "test['fare_for_duration'] = test['fare_for_duration'].astype(np.float32)\n",
    "#test['fare_for_distance'] = test['fare_for_distance'].astype(np.float32)\n",
    "test['fare_for_time'] = test['fare_for_time'].astype(np.float32)\n",
    "#test['distance_for_time'] = test['distance_for_time'].astype(np.float32)\n",
    "test['meter_waiting_to_duration'] = test['meter_waiting_to_duration'].astype(np.float32)\n",
    "test['additional_fare_to_duration'] = test['additional_fare_to_duration'].astype(np.float32)\n",
    "#test['additional_fare_to_distance'] = test['additional_fare_to_distance'].astype(np.float32)\n",
    "test['additional_fare_to_fare'] = test['additional_fare_to_fare'].astype(np.float32)\n",
    "test['mtr_wating_fare_to_waiting_duration'] = test['mtr_wating_fare_to_waiting_duration'].astype(np.float32)\n",
    "test['additional_fare_to_full_time'] = test['additional_fare_to_full_time'].astype(np.float32)\n",
    "test['full_waiting_fare_to_full_time'] = test['full_waiting_fare_to_full_time'].astype(np.float32)\n",
    "test['net_fare_for_durtion'] = test['net_fare_for_durtion'].astype(np.float32)\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    if(row['label'] == \"correct\"):\n",
    "        train.at[index, 'num_label'] = 1\n",
    "    else:\n",
    "        train.at[index, 'num_label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# 'fare_for_distance',\n",
    "# 'distance_for_time', 'additional_fare_to_distance', 'distance_for_time', 'only_fare_for_duration',\n",
    "predictor_cols = ['additional_fare', 'net_fare_for_durtion', 'full_waiting_fare_to_full_time', 'additional_fare_to_full_time', 'mtr_wating_fare_to_waiting_duration', 'fare_for_time', 'meter_waiting_to_duration', 'fare_for_duration', 'additional_fare_to_duration', 'additional_fare_to_fare', 'pick_hour', 'drop_hour', 'pick_lat', 'pick_lon', 'direct_distance', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'fare']\n",
    "train_X_ = train[predictor_cols]\n",
    "test_X = test[predictor_cols]\n",
    "train_X_.replace([np.inf, -np.inf], np.nan)\n",
    "test_X.replace([np.inf, -np.inf], np.nan)\n",
    "train_X_.fillna(train_X_.mean(), inplace=True)\n",
    "test_X.fillna(test_X.mean(), inplace=True)\n",
    "\n",
    "train_y_ = train.num_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>net_fare_for_durtion</th>\n",
       "      <th>full_waiting_fare_to_full_time</th>\n",
       "      <th>additional_fare_to_full_time</th>\n",
       "      <th>mtr_wating_fare_to_waiting_duration</th>\n",
       "      <th>fare_for_time</th>\n",
       "      <th>meter_waiting_to_duration</th>\n",
       "      <th>fare_for_duration</th>\n",
       "      <th>additional_fare_to_duration</th>\n",
       "      <th>additional_fare_to_fare</th>\n",
       "      <th>pick_hour</th>\n",
       "      <th>drop_hour</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>direct_distance</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.311535</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301024</td>\n",
       "      <td>0.067146</td>\n",
       "      <td>0.324125</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>5.092770</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>270.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.236852</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213892</td>\n",
       "      <td>0.059418</td>\n",
       "      <td>0.250126</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.050396</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>3.168058</td>\n",
       "      <td>791.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>197.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.267838</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262753</td>\n",
       "      <td>0.073597</td>\n",
       "      <td>0.277498</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>0.033639</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.305395</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>301.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>0.027923</td>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.046206</td>\n",
       "      <td>0.100054</td>\n",
       "      <td>0.453177</td>\n",
       "      <td>0.111432</td>\n",
       "      <td>0.017559</td>\n",
       "      <td>0.113147</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>0.861946</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>15.663800</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>82.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.719651</td>\n",
       "      <td>0.183581</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>0.179765</td>\n",
       "      <td>0.369423</td>\n",
       "      <td>0.191638</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.036870</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.87441</td>\n",
       "      <td>79.8615</td>\n",
       "      <td>8.147782</td>\n",
       "      <td>1702.858077</td>\n",
       "      <td>629.074231</td>\n",
       "      <td>32.057666</td>\n",
       "      <td>112.466832</td>\n",
       "      <td>358.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17171</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.217587</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.149603</td>\n",
       "      <td>0.110979</td>\n",
       "      <td>0.230117</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>0.050297</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>7.29073</td>\n",
       "      <td>80.6367</td>\n",
       "      <td>2.105376</td>\n",
       "      <td>838.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>5.421900</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>198.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17172</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.265332</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265402</td>\n",
       "      <td>0.198977</td>\n",
       "      <td>0.270214</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.90569</td>\n",
       "      <td>79.8516</td>\n",
       "      <td>10.868377</td>\n",
       "      <td>2151.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>581.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17173</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.249810</td>\n",
       "      <td>0.027487</td>\n",
       "      <td>0.027487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204290</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.289734</td>\n",
       "      <td>0.039924</td>\n",
       "      <td>0.121107</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>7.09210</td>\n",
       "      <td>79.9000</td>\n",
       "      <td>1.045518</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>76.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17174</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.143135</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113455</td>\n",
       "      <td>0.134033</td>\n",
       "      <td>0.155373</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.073013</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.94540</td>\n",
       "      <td>79.8768</td>\n",
       "      <td>2.879077</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>133.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17175</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.331472</td>\n",
       "      <td>0.038315</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.341564</td>\n",
       "      <td>0.080153</td>\n",
       "      <td>0.371548</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.096268</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.90257</td>\n",
       "      <td>79.9557</td>\n",
       "      <td>2.115875</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.224300</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>98.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17176 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       additional_fare  net_fare_for_durtion  full_waiting_fare_to_full_time  \\\n",
       "0            10.500000              0.311535                        0.011006   \n",
       "1            10.500000              0.236852                        0.010802   \n",
       "2            10.500000              0.267838                        0.008550   \n",
       "3            10.500000              0.093873                        0.027923   \n",
       "4            13.719651              0.183581                        0.018727   \n",
       "...                ...                   ...                             ...   \n",
       "17171        10.500000              0.217587                        0.011521   \n",
       "17172        10.500000              0.265332                        0.004011   \n",
       "17173        10.500000              0.249810                        0.027487   \n",
       "17174        10.500000              0.143135                        0.008140   \n",
       "17175        10.500000              0.331472                        0.038315   \n",
       "\n",
       "       additional_fare_to_full_time  mtr_wating_fare_to_waiting_duration  \\\n",
       "0                          0.011006                             0.000000   \n",
       "1                          0.010802                             0.000000   \n",
       "2                          0.008550                             0.000000   \n",
       "3                          0.011206                             0.046206   \n",
       "4                          0.005613                             0.043231   \n",
       "...                             ...                                  ...   \n",
       "17171                      0.007598                             0.009967   \n",
       "17172                      0.004011                             0.000000   \n",
       "17173                      0.027487                             0.000000   \n",
       "17174                      0.008140                             0.000000   \n",
       "17175                      0.034314                             0.027825   \n",
       "\n",
       "       fare_for_time  meter_waiting_to_duration  fare_for_duration  \\\n",
       "0           0.301024                   0.067146           0.324125   \n",
       "1           0.213892                   0.059418           0.250126   \n",
       "2           0.262753                   0.073597           0.277498   \n",
       "3           0.100054                   0.453177           0.111432   \n",
       "4           0.179765                   0.369423           0.191638   \n",
       "...              ...                        ...                ...   \n",
       "17171       0.149603                   0.110979           0.230117   \n",
       "17172       0.265402                   0.198977           0.270214   \n",
       "17173       0.204290                   0.034221           0.289734   \n",
       "17174       0.113455                   0.134033           0.155373   \n",
       "17175       0.341564                   0.080153           0.371548   \n",
       "\n",
       "       additional_fare_to_duration  additional_fare_to_fare  pick_hour  \\\n",
       "0                         0.012590                 0.037391          0   \n",
       "1                         0.013274                 0.050396          0   \n",
       "2                         0.009660                 0.033639          1   \n",
       "3                         0.017559                 0.113147          2   \n",
       "4                         0.008057                 0.036870          3   \n",
       "...                            ...                      ...        ...   \n",
       "17171                     0.012530                 0.050297         22   \n",
       "17172                     0.004881                 0.017745         23   \n",
       "17173                     0.039924                 0.121107         23   \n",
       "17174                     0.012238                 0.073013         23   \n",
       "17175                     0.040076                 0.096268         23   \n",
       "\n",
       "       drop_hour  pick_lat  pick_lon  direct_distance     duration  \\\n",
       "0              0   6.86252   79.8993         5.092770   834.000000   \n",
       "1              1   6.88589   79.8984         3.168058   791.000000   \n",
       "2              1   6.90839   79.8651         6.305395  1087.000000   \n",
       "3              2   6.92570   79.8895         0.861946   598.000000   \n",
       "4              3   6.87441   79.8615         8.147782  1702.858077   \n",
       "...          ...       ...       ...              ...          ...   \n",
       "17171         22   7.29073   80.6367         2.105376   838.000000   \n",
       "17172         23   6.90569   79.8516        10.868377  2151.000000   \n",
       "17173         23   7.09210   79.9000         1.045518   263.000000   \n",
       "17174         23   6.94540   79.8768         2.879077   858.000000   \n",
       "17175         23   6.90257   79.9557         2.115875   262.000000   \n",
       "\n",
       "       meter_waiting  meter_waiting_fare  meter_waiting_till_pickup    fare  \n",
       "0          56.000000            0.000000                  64.000000  270.32  \n",
       "1          47.000000            0.000000                 134.000000  197.85  \n",
       "2          80.000000            0.000000                  61.000000  301.64  \n",
       "3         271.000000           15.663800                  68.000000   82.30  \n",
       "4         629.074231           32.057666                 112.466832  358.39  \n",
       "...              ...                 ...                        ...     ...  \n",
       "17171      93.000000            5.421900                 451.000000  198.26  \n",
       "17172     428.000000            0.000000                  39.000000  581.23  \n",
       "17173       9.000000            0.000000                 110.000000   76.20  \n",
       "17174     115.000000            0.000000                 317.000000  133.31  \n",
       "17175      21.000000            1.224300                  23.000000   98.57  \n",
       "\n",
       "[17176 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>net_fare_for_durtion</th>\n",
       "      <th>full_waiting_fare_to_full_time</th>\n",
       "      <th>additional_fare_to_full_time</th>\n",
       "      <th>mtr_wating_fare_to_waiting_duration</th>\n",
       "      <th>fare_for_time</th>\n",
       "      <th>meter_waiting_to_duration</th>\n",
       "      <th>fare_for_duration</th>\n",
       "      <th>additional_fare_to_duration</th>\n",
       "      <th>additional_fare_to_fare</th>\n",
       "      <th>pick_hour</th>\n",
       "      <th>drop_hour</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>direct_distance</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.299049</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>0.267557</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.310413</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.035027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.83454</td>\n",
       "      <td>79.8750</td>\n",
       "      <td>6.705702</td>\n",
       "      <td>924</td>\n",
       "      <td>42</td>\n",
       "      <td>2.44860</td>\n",
       "      <td>148</td>\n",
       "      <td>289.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.447682</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440714</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.450153</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.91168</td>\n",
       "      <td>79.8723</td>\n",
       "      <td>41.558513</td>\n",
       "      <td>4249</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>91</td>\n",
       "      <td>1912.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.245387</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>0.248471</td>\n",
       "      <td>0.164304</td>\n",
       "      <td>0.252153</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.92145</td>\n",
       "      <td>79.8478</td>\n",
       "      <td>5.916678</td>\n",
       "      <td>1552</td>\n",
       "      <td>255</td>\n",
       "      <td>2.65880</td>\n",
       "      <td>23</td>\n",
       "      <td>394.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.311299</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>0.334026</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.063706</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.77433</td>\n",
       "      <td>79.9416</td>\n",
       "      <td>3.301761</td>\n",
       "      <td>462</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>198</td>\n",
       "      <td>154.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.153072</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.026831</td>\n",
       "      <td>0.153002</td>\n",
       "      <td>0.481572</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.066468</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6.97968</td>\n",
       "      <td>79.9130</td>\n",
       "      <td>2.588542</td>\n",
       "      <td>814</td>\n",
       "      <td>392</td>\n",
       "      <td>12.36920</td>\n",
       "      <td>69</td>\n",
       "      <td>147.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.204960</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.057485</td>\n",
       "      <td>0.210688</td>\n",
       "      <td>0.248984</td>\n",
       "      <td>0.211054</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.026317</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>6.85103</td>\n",
       "      <td>79.9567</td>\n",
       "      <td>3.934272</td>\n",
       "      <td>1723</td>\n",
       "      <td>429</td>\n",
       "      <td>24.83332</td>\n",
       "      <td>3</td>\n",
       "      <td>388.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.268033</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252728</td>\n",
       "      <td>0.058055</td>\n",
       "      <td>0.275653</td>\n",
       "      <td>0.007620</td>\n",
       "      <td>0.026899</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>6.91293</td>\n",
       "      <td>79.9656</td>\n",
       "      <td>7.517433</td>\n",
       "      <td>1378</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>125</td>\n",
       "      <td>379.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.236856</td>\n",
       "      <td>0.024311</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.022043</td>\n",
       "      <td>0.214297</td>\n",
       "      <td>0.133971</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>0.085165</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>6.85718</td>\n",
       "      <td>79.9081</td>\n",
       "      <td>2.057225</td>\n",
       "      <td>418</td>\n",
       "      <td>56</td>\n",
       "      <td>3.28440</td>\n",
       "      <td>93</td>\n",
       "      <td>112.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.128607</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.056061</td>\n",
       "      <td>0.133736</td>\n",
       "      <td>0.341646</td>\n",
       "      <td>0.135153</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.040547</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>6.91289</td>\n",
       "      <td>79.8846</td>\n",
       "      <td>3.900888</td>\n",
       "      <td>1604</td>\n",
       "      <td>548</td>\n",
       "      <td>31.67440</td>\n",
       "      <td>17</td>\n",
       "      <td>248.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.174465</td>\n",
       "      <td>0.017848</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.044868</td>\n",
       "      <td>0.176288</td>\n",
       "      <td>0.406949</td>\n",
       "      <td>0.180649</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>6.91682</td>\n",
       "      <td>79.9192</td>\n",
       "      <td>5.435270</td>\n",
       "      <td>1698</td>\n",
       "      <td>691</td>\n",
       "      <td>32.88820</td>\n",
       "      <td>42</td>\n",
       "      <td>339.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8576 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      additional_fare  net_fare_for_durtion  full_waiting_fare_to_full_time  \\\n",
       "0                10.5              0.299049                        0.011624   \n",
       "1                10.5              0.447682                        0.002408   \n",
       "2                10.5              0.245387                        0.007191   \n",
       "3                10.5              0.311299                        0.015533   \n",
       "4                10.5              0.153072                        0.017937   \n",
       "...               ...                   ...                             ...   \n",
       "8571             10.5              0.204960                        0.016396   \n",
       "8572             10.5              0.268033                        0.006633   \n",
       "8573             10.5              0.236856                        0.024311   \n",
       "8574             10.5              0.128607                        0.019444   \n",
       "8575             10.5              0.174465                        0.017848   \n",
       "\n",
       "      additional_fare_to_full_time  mtr_wating_fare_to_waiting_duration  \\\n",
       "0                         0.009425                             0.012887   \n",
       "1                         0.002408                             0.000000   \n",
       "2                         0.005738                             0.009564   \n",
       "3                         0.015533                             0.000000   \n",
       "4                         0.008235                             0.026831   \n",
       "...                            ...                                  ...   \n",
       "8571                      0.004872                             0.057485   \n",
       "8572                      0.006633                             0.000000   \n",
       "8573                      0.018519                             0.022043   \n",
       "8574                      0.004841                             0.056061   \n",
       "8575                      0.004319                             0.044868   \n",
       "\n",
       "      fare_for_time  meter_waiting_to_duration  fare_for_duration  \\\n",
       "0          0.267557                   0.045455           0.310413   \n",
       "1          0.440714                   0.004707           0.450153   \n",
       "2          0.248471                   0.164304           0.252153   \n",
       "3          0.233818                   0.034632           0.334026   \n",
       "4          0.153002                   0.481572           0.165972   \n",
       "...             ...                        ...                ...   \n",
       "8571       0.210688                   0.248984           0.211054   \n",
       "8572       0.252728                   0.058055           0.275653   \n",
       "8573       0.214297                   0.133971           0.261975   \n",
       "8574       0.133736                   0.341646           0.135153   \n",
       "8575       0.176288                   0.406949           0.180649   \n",
       "\n",
       "      additional_fare_to_duration  additional_fare_to_fare  pick_hour  \\\n",
       "0                        0.011364                 0.035027          0   \n",
       "1                        0.002471                 0.005460          1   \n",
       "2                        0.006765                 0.025958          5   \n",
       "3                        0.022727                 0.063706          5   \n",
       "4                        0.012899                 0.066468          7   \n",
       "...                           ...                      ...        ...   \n",
       "8571                     0.006094                 0.026317         21   \n",
       "8572                     0.007620                 0.026899         21   \n",
       "8573                     0.025120                 0.085165         22   \n",
       "8574                     0.006546                 0.040547         22   \n",
       "8575                     0.006184                 0.029989         22   \n",
       "\n",
       "      drop_hour  pick_lat  pick_lon  direct_distance  duration  meter_waiting  \\\n",
       "0             0   6.83454   79.8750         6.705702       924             42   \n",
       "1             2   6.91168   79.8723        41.558513      4249             20   \n",
       "2             5   6.92145   79.8478         5.916678      1552            255   \n",
       "3             5   6.77433   79.9416         3.301761       462             16   \n",
       "4             7   6.97968   79.9130         2.588542       814            392   \n",
       "...         ...       ...       ...              ...       ...            ...   \n",
       "8571         21   6.85103   79.9567         3.934272      1723            429   \n",
       "8572         22   6.91293   79.9656         7.517433      1378             80   \n",
       "8573         22   6.85718   79.9081         2.057225       418             56   \n",
       "8574         22   6.91289   79.8846         3.900888      1604            548   \n",
       "8575         23   6.91682   79.9192         5.435270      1698            691   \n",
       "\n",
       "      meter_waiting_fare  meter_waiting_till_pickup     fare  \n",
       "0                2.44860                        148   289.27  \n",
       "1                0.00000                         91  1912.70  \n",
       "2                2.65880                         23   394.00  \n",
       "3                0.00000                        198   154.32  \n",
       "4               12.36920                         69   147.47  \n",
       "...                  ...                        ...      ...  \n",
       "8571            24.83332                          3   388.48  \n",
       "8572             0.00000                        125   379.85  \n",
       "8573             3.28440                         93   112.79  \n",
       "8574            31.67440                         17   248.46  \n",
       "8575            32.88820                         42   339.63  \n",
       "\n",
       "[8576 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(train_X_, train_y_, test_size = 0.2, train_size = 0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    mse = mean_squared_error(test_labels, predictions)\n",
    "    mae = mean_absolute_error(test_labels, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    score=cross_val_score(model, test_features, test_labels, cv=10)\n",
    "    accuracy = accuracy_score(test_labels, predictions.round())\n",
    "    print('Model Performance')\n",
    "    print('Accuracy:%f'%accuracy)\n",
    "    print(\"Mean cross validation score:%f\"%score.mean())\n",
    "    print('Mean Squared Error : %.4f' % mse)\n",
    "    print('Root MSE : %.4f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy:0.956345\n",
      "Mean cross validation score:0.499015\n",
      "Mean Squared Error : 0.0366\n",
      "Root MSE : 0.1914\n",
      "F1 score: 0.959347\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestRegressor(n_estimators=100, random_state = 0)\n",
    "random_forest_model.fit(train_X, train_y)\n",
    "\n",
    "evaluate(random_forest_model, val_X, val_y)\n",
    "\n",
    "pred_classes = random_forest_model.predict(val_X)\n",
    "predi = []\n",
    "for x in range(len(pred_classes)):\n",
    "    predi.append(bool(pred_classes[x]))\n",
    "    \n",
    "pred_classes = np.array(predi)\n",
    "\n",
    "f1 = f1_score(val_y, pred_classes)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy:0.941793\n",
      "Mean cross validation score:0.323674\n",
      "Mean Squared Error : 0.0471\n",
      "Root MSE : 0.2170\n",
      "F1 score: 0.960211\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree_model = DecisionTreeRegressor(min_samples_split=100,\n",
    "        max_features=\"auto\", random_state=50, \n",
    "        max_depth=100)\n",
    "my_decision_tree_model.fit(train_X, train_y)\n",
    "\n",
    "evaluate(my_decision_tree_model, val_X, val_y)\n",
    "\n",
    "pred_classes = my_decision_tree_model.predict(val_X)\n",
    "predi = []\n",
    "for x in range(len(pred_classes)):\n",
    "    predi.append(bool(pred_classes[x]))\n",
    "    \n",
    "pred_classes = np.array(predi)\n",
    "\n",
    "f1 = f1_score(val_y, pred_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy:0.940338\n",
      "Mean cross validation score:0.061829\n",
      "Mean Squared Error : 0.0914\n",
      "Root MSE : 0.3023\n",
      "F1 score: 0.951000\n"
     ]
    }
   ],
   "source": [
    "Ada_boost_model = AdaBoostRegressor()\n",
    "Ada_boost_model.fit(train_X, train_y)\n",
    "\n",
    "evaluate(Ada_boost_model, val_X, val_y)\n",
    "\n",
    "pred_classes = Ada_boost_model.predict(val_X)\n",
    "predi = []\n",
    "for x in range(len(pred_classes)):\n",
    "    predi.append(bool(pred_classes[x]))\n",
    "    \n",
    "pred_classes = np.array(predi)\n",
    "\n",
    "f1 = f1_score(val_y, pred_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.911816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=1, penalty='l1', solver='liblinear')\n",
    "param_grid = {'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
    "'''{\n",
    "    'n_estimators' : [10, 200],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2', 0.5]\n",
    "}'''\n",
    "gs_model = GridSearchCV(clf, param_grid = param_grid, scoring = 'recall')\n",
    "gs_model.fit(train_X, train_y)\n",
    "\n",
    "predictions = gs_model.predict(val_X)\n",
    "accuracy = accuracy_score(val_y, predictions.round())\n",
    "print('Accuracy:%f'%accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "687/687 [==============================] - 4s 6ms/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9460 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\n",
      "Epoch 2/5\n",
      "687/687 [==============================] - 4s 6ms/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9461 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\n",
      "Epoch 3/5\n",
      "687/687 [==============================] - 4s 6ms/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9460 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\n",
      "Epoch 4/5\n",
      "687/687 [==============================] - 4s 5ms/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9461 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\n",
      "Epoch 5/5\n",
      "687/687 [==============================] - 4s 5ms/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9461 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\n",
      "F1 score: 0.951000\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Dense(15))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse', metrics=['accuracy',f1_m])\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "#results = cross_val_score(estimator, train_X, train_y, cv=kfold)\n",
    "#print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "model.fit(train_X_.values, train_y_.values,\n",
    "          batch_size=20,\n",
    "          epochs=5,\n",
    "          validation_split = 0.2,\n",
    "          verbose = 1,\n",
    "          shuffle=True)\n",
    "\n",
    "#evaluate(model, val_X, val_y)\n",
    "pred_classes = model.predict(val_X)\n",
    "predi = []\n",
    "for x in range(len(pred_classes)):\n",
    "    predi.append(bool(pred_classes[x]))\n",
    "    \n",
    "pred_classes = np.array(predi)\n",
    "\n",
    "f1 = f1_score(val_y, pred_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xg_model = xgboost.XGBClassifier()\n",
    "\n",
    "score=cross_val_score(xg_model, train_X, train_y, cv=10)\n",
    "xg_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.954016\n",
      "F1 score: 0.974881\n"
     ]
    }
   ],
   "source": [
    "def xg_evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    #mse = mean_squared_error(test_labels, predictions)\n",
    "    #mae = mean_absolute_error(test_labels, predictions)\n",
    "    #rmse = np.sqrt(mse)\n",
    "    #score=cross_val_score(model, test_features, test_labels, cv=10)\n",
    "    accuracy = accuracy_score(test_labels, predictions.round())\n",
    "    #print('Model Performance')\n",
    "    print('Accuracy:%f'%accuracy)\n",
    "    #print(\"Mean cross validation score:%f\"%score.mean())\n",
    "    #print('Mean Squared Error : %.4f' % mse)\n",
    "    #print('Root MSE : %.4f' % rmse)\n",
    "xg_evaluate(xg_model, val_X, val_y)\n",
    "pred_classes = xg_model.predict(val_X)\n",
    "predi = []\n",
    "for x in range(len(pred_classes)):\n",
    "    predi.append(bool(pred_classes[x]))\n",
    "    \n",
    "pred_classes = np.array(predi)\n",
    "\n",
    "f1 = f1_score(val_y, pred_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.946740\n",
      "F1 score: 0.971140\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "knn_classifier.fit(train_X, train_y)\n",
    "\n",
    "def knn_evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    #mse = mean_squared_error(test_labels, predictions)\n",
    "    #mae = mean_absolute_error(test_labels, predictions)\n",
    "    #rmse = np.sqrt(mse)\n",
    "    #score=cross_val_score(model, test_features, test_labels, cv=10)\n",
    "    accuracy = accuracy_score(test_labels, predictions.round())\n",
    "    #print('Model Performance')\n",
    "    print('Accuracy:%f'%accuracy)\n",
    "    #print(\"Mean cross validation score:%f\"%score.mean())\n",
    "    #print('Mean Squared Error : %.4f' % mse)\n",
    "    #print('Root MSE : %.4f' % rmse)\n",
    "knn_evaluate(knn_classifier, val_X, val_y)\n",
    "\n",
    "pred_classes = knn_classifier.predict(val_X)\n",
    "predi = []\n",
    "for x in range(len(pred_classes)):\n",
    "    predi.append(bool(pred_classes[x]))\n",
    "    \n",
    "pred_classes = np.array(predi)\n",
    "f1 = f1_score(val_y, pred_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
